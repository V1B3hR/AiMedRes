# AiMedRes Debugging Usage Guide

## Overview

The AiMedRes debugging process implements a comprehensive, phase-based approach to debugging AI/ML systems. This guide covers both Phase 1 (Environment & Reproducibility) and Phase 2 (Data Integrity & Preprocessing) debugging.

## Phase 1: Environment & Reproducibility Checks âœ… COMPLETE

### Running Phase 1 Debugging

#### Basic Usage
```bash
python debug/phase1_environment_debug.py
```

#### With Verbose Output
```bash
python debug/phase1_environment_debug.py --verbose
```

#### View Help
```bash
python debug/phase1_environment_debug.py --help
```

### What Phase 1 Checks

#### Subphase 1.1: Environment Setup Verification âœ… COMPLETE
- âœ… Python version (requires >=3.10)
- âœ… Platform information
- âœ… Core dependencies (SQLAlchemy, psycopg2, pgvector, sentence_transformers, yaml)
- âœ… ML dependencies (numpy, pandas, scikit-learn, matplotlib, seaborn, torch, xgboost, kagglehub, scipy, joblib)
- âœ… GPU/CUDA availability check
- âœ… Environment variables from .env file

#### Subphase 1.2: Reproducibility Checks âœ… COMPLETE
- âœ… Random seed implementation in training scripts
- âœ… Reproducibility test with NumPy and Python random
- âœ… Environment documentation generation

#### Subphase 1.3: Version Control Verification âœ… COMPLETE
- âœ… Git repository status
- âœ… .gitignore patterns for ML projects
- âœ… DVC (Data Version Control) setup
- âœ… Output directory structure

## Phase 2: Data Integrity & Preprocessing Debugging âœ… COMPLETE

### Running Phase 2 Debugging

#### Basic Usage
```bash
python debug/phase2_data_integrity_debug.py
```

#### With Verbose Output
```bash
python debug/phase2_data_integrity_debug.py --verbose
```

#### Custom Output Directory
```bash
python debug/phase2_data_integrity_debug.py --output-dir custom_debug_output
```

### What Phase 2 Checks

#### Subphase 2.1: Data Integrity Validation âœ… COMPLETE
- âœ… Missing values analysis across all datasets
- âœ… Duplicate detection and reporting
- âœ… Outlier identification using IQR method
- âœ… Data type validation and consistency checks
- âœ… Column-level analysis for data quality metrics

#### Subphase 2.2: Preprocessing Routines Check âœ… COMPLETE
- âœ… Training script analysis for preprocessing patterns
- âœ… Feature scaling implementation verification
- âœ… Data encoding pattern detection
- âœ… Cross-validation and splitting methodology review
- âœ… Preprocessing pipeline testing

#### Subphase 2.3: Data Visualization & Class Balance âœ… COMPLETE
- âœ… Missing data heatmaps generation
- âœ… Feature distribution analysis and visualization
- âœ… Class balance assessment and visualization
- âœ… Correlation matrix generation for numeric features
- âœ… Automated visualization export to debug/visualizations/

### Phase 2 Generated Files

The Phase 2 script generates several output files:

1. **`debug/phase2_results.json`** - Comprehensive Phase 2 results and findings
2. **`debug/visualizations/`** - Directory containing:
   - `correlation_*.png` - Feature correlation matrices
   - `distributions_*.png` - Feature distribution plots
   - `missing_data_*.png` - Missing data pattern heatmaps
   - `class_balance_*.png` - Class balance visualizations

### Current Status: Multiple Phases Complete

#### âœ… Phase 1 Complete
- All environment dependencies installed and verified
- Reproducibility tests passing
- Version control properly configured

#### âœ… Phase 2 Complete  
- Data integrity validation passed
- Preprocessing routines verified
- Visualizations generated successfully

#### âœ… Phase 8 Complete
- Feature importance plots for tree-based models generated
- Partial dependence plots created for key features
- Enhanced confusion matrices with precision, recall, F1 displayed
- 15+ high-quality visualizations produced

## Phase 8: Model Visualization & Interpretability âœ… COMPLETE

### Running Phase 8 Debugging

#### Basic Usage
```bash
python debug/phase8_model_visualization.py
```

#### With Verbose Output
```bash
python debug/phase8_model_visualization.py --verbose
```

#### Custom Data Source
```bash
# Use synthetic data (default)
python debug/phase8_model_visualization.py --data-source synthetic

# Use custom CSV file
python debug/phase8_model_visualization.py --data-source path/to/data.csv
```

### What Phase 8 Analyzes

#### Subphase 8.1: Feature Importance for Tree-Based Models âœ… COMPLETE
- âœ… Extracts feature importances from DecisionTree, RandomForest, and GradientBoosting
- âœ… Generates bar plots showing top 15 most important features
- âœ… Saves feature importance data to CSV files for further analysis
- âœ… Creates color-coded visualizations with viridis palette
- âœ… Logs top 5 features for each model with importance scores

#### Subphase 8.2: Partial Dependence Plots âœ… COMPLETE
- âœ… Identifies top 4 most important features from each model
- âœ… Generates 1D partial dependence plots showing individual feature effects
- âœ… Creates 2D partial dependence plots for top feature interactions
- âœ… Uses sklearn.inspection.partial_dependence for accurate calculations
- âœ… Visualizes how predictions change with feature values

#### Subphase 8.3: Enhanced Confusion Matrices âœ… COMPLETE
- âœ… Generates confusion matrices with raw counts
- âœ… Creates normalized confusion matrices showing percentages
- âœ… Produces per-class metrics visualizations (precision, recall, F1)
- âœ… Displays accuracy and macro-averaged metrics
- âœ… Saves comprehensive classification reports to results JSON

### Phase 8 Generated Files

The Phase 8 script generates several output files:

1. **`debug/phase8_results.json`** - Comprehensive Phase 8 results including:
   - Feature importance rankings for each model
   - Partial dependence analysis results
   - Confusion matrix data and classification reports
   - Model performance metrics

2. **`debug/visualizations/`** - Directory containing:
   - `feature_importance_*.png` - Feature importance bar plots (3 files)
   - `feature_importance_*.csv` - Feature importance data tables (3 files)
   - `partial_dependence_*.png` - 1D PDP plots showing individual feature effects (3 files)
   - `partial_dependence_2d_*.png` - 2D PDP plots showing feature interactions (3 files)
   - `confusion_matrix_*.png` - Enhanced confusion matrices with counts and percentages (3 files)
   - `classification_metrics_*.png` - Per-class precision, recall, F1 visualizations (3 files)

### Phase 8 Key Features

- **Automated Model Training**: Trains DecisionTree, RandomForest, and GradientBoosting classifiers
- **Multiple Visualization Types**: 15+ plots generated automatically
- **Feature Insights**: Identifies most important features across all models
- **Interactive Analysis**: Partial dependence shows how features affect predictions
- **Performance Metrics**: Detailed per-class and overall performance evaluation
- **Publication Quality**: High-resolution (300 DPI) plots ready for reports

### Example Output

```
ðŸš€ Starting Phase 8: Model Visualization & Interpretability

SUBPHASE 8.1: FEATURE IMPORTANCE FOR TREE-BASED MODELS
  âœ“ RandomForest trained (Test Accuracy: 0.770)
  Top 5 features for RandomForest:
    age: 0.3178
    bmi: 0.1838
    blood_pressure: 0.1755
    cholesterol: 0.1215
    glucose: 0.1089

SUBPHASE 8.2: PARTIAL DEPENDENCE PLOTS
  âœ“ Saved 1D partial dependence plots
  âœ“ Saved 2D partial dependence plot

SUBPHASE 8.3: ENHANCED CONFUSION MATRICES
  Overall metrics for RandomForest:
    Accuracy:  0.770
    Macro Avg - Precision: 0.770, Recall: 0.770, F1: 0.770

âœ… Phase 8 Model Visualization & Interpretability COMPLETE
```

## Next Steps

With Phases 1, 2, and 8 complete, you can proceed to:
- Phase 3: Code Sanity & Logical Error Checks
- Phase 4: Model Architecture Verification
- Phase 5: Cross-Validation Implementation
- Phase 6: Hyperparameter Tuning & Search
- Phase 7: Model Training & Evaluation
- Phase 9: Error Analysis & Edge Cases
- Phase 10: Final Model & System Validation
- etc. (as outlined in debug/debuglist.md)

## Troubleshooting

### Phase 1 Common Issues

1. **Missing dependencies**: Install using pip as shown above
2. **CUDA not available**: This is expected in CPU-only environments
3. **Uncommitted changes**: This is just a warning, not a failure
4. **Environment variables not loading**: Make sure .env file exists and has correct format

### Phase 2 Common Issues

1. **No data files found**: Ensure CSV data files exist in the repository
2. **Visualization errors**: Check matplotlib backend configuration for headless environments
3. **Preprocessing analysis incomplete**: Review training scripts for standard preprocessing patterns

### Phase 8 Common Issues

1. **Import errors**: Ensure sklearn, matplotlib, seaborn, numpy, pandas are installed
2. **Partial dependence errors**: Some models may not support PDP - only tree-based models are used
3. **Memory issues with large datasets**: Phase 8 uses full dataset - consider sampling for very large datasets
4. **Missing models**: Phase 8 trains its own models - Phase 7 results are optional

### Clean Environment Test
To test in a clean environment:
```bash
# Reset and test both phases
git status  # Check current state
python debug/phase1_environment_debug.py --verbose
python debug/phase2_data_integrity_debug.py --verbose
```

## Implementation Details

The Phase 1 script is a comprehensive tool that:
- Automatically loads .env files
- Checks package versions against requirements
- Tests reproducibility with actual computations
- Documents the complete environment state
- Provides actionable recommendations

This establishes a solid foundation for the subsequent debugging phases in the AiMedRes debugging methodology.